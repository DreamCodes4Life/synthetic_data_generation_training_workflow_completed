{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Synthetic Data Generation and Training Workflow with Warehouse Sim Ready Assets\n",
    "\n",
    "This notebook is the second part of the SDG and Training Workflow. Here, we will be focusing on training an Object Detection Network with TAO toolkit\n",
    "\n",
    "A high level overview of the steps:\n",
    "* Pulling TAO Docker Container\n",
    "* Training Detectnet_v2 model with generated Synthetic Data \n",
    "* Visualizing Model Performance on Sample Real World Data\n",
    "\n",
    "`This notebook is very similar to the cloud training notebook, only mounted directories and paths for the docker containers are changed. The data, model and training, evaluation and inference steps are identical` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If Isaac Sim is installed locally, ensure that data generation is complete. Run the `generate_data.sh` script in this folder. Ensure the path to Isaac Sim is set correctly in the script (`ISAAC_SIM_PATH` corresponds to where Isaac Sim is installed locally on your workstation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "This notebook shows an example usecase of Object Detection using DetectNet_v2 in the Train Adapt Optimize (TAO) Toolkit. We will train the model with Synthetic Data generated previously.\n",
    "\n",
    "1. [Set up TAO via Docker container](#head-1)\n",
    "2. [Download Pretrained model](#head-2)\n",
    "3. [Convert Dataset to TFRecords for TAO](#head-3)\n",
    "4. [Provide training specification](#head-4)\n",
    "5. [Run TAO training](#head-5)\n",
    "6. [Evaluate trained model](#head-6)\n",
    "7. [Visualize Model Predictions on Real World Data](#head-7)\n",
    "8. [Next Steps](#head-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up TAO via Docker Container <a class=\"anchor\" id=\"head-1\"></a>\n",
    "\n",
    "* We will follow the pre-requisites section of [instructions](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_quick_start_guide.html#running-tao-toolkit) for using TAO toolkit. Make sure that the pre-requisite steps are completed (installing `docker`, `nvidia container toolkit` and `docker login nvcr.io`)\n",
    "\n",
    "* The docker container being used for training will be pulled in the cells below, make sure you have completed the pre-requisite steps and `docker login nvcr.io` to allow pulling of the container from NGC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DOCKER_REGISTRY=nvcr.io\n",
      "env: DOCKER_NAME=nvidia/tao/tao-toolkit\n",
      "env: DOCKER_TAG=4.0.0-tf1.15.5 ## for TensorFlow docker\n",
      "env: DOCKER_CONTAINER=nvcr.io/nvidia/tao/tao-toolkit:4.0.0-tf1.15.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%env DOCKER_REGISTRY=nvcr.io\n",
    "%env DOCKER_NAME=nvidia/tao/tao-toolkit\n",
    "%env DOCKER_TAG=4.0.0-tf1.15.5 ## for TensorFlow docker\n",
    "\n",
    "%env DOCKER_CONTAINER=nvcr.io/nvidia/tao/tao-toolkit:4.0.0-tf1.15.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Pretrained Model <a class=\"anchor\" id=\"head-2\"></a>\n",
    "\n",
    "* We will use the `detectnet_v2` Object Detection model with a `resnet18` backbone\n",
    "* Make sure the `LOCAL_PROJECT_DIR` environment variable has the path of this cloned repository in the cell below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/labs/synthetic_data_generation_training_workflow\n"
     ]
    }
   ],
   "source": [
    "# os.environ[\"LOCAL_PROJECT_DIR\"] = \"<LOCAL_PATH_OF_CLONED_REPO>\"\n",
    "os.environ[\"LOCAL_PROJECT_DIR\"] = os.path.dirname(os.getcwd()) # This is the location of the root of the cloned repo\n",
    "print(os.environ[\"LOCAL_PROJECT_DIR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18.hdf5       100%[===================>]  89.02M  8.77MB/s    in 10s     \n"
     ]
    }
   ],
   "source": [
    "!wget --quiet --show-progress --progress=bar:force:noscroll --auth-no-challenge --no-check-certificate \\\n",
    "        https://api.ngc.nvidia.com/v2/models/nvidia/tao/pretrained_detectnet_v2/versions/resnet18/files/resnet18.hdf5 \\\n",
    "        -P  $LOCAL_PROJECT_DIR/local/training/tao/pretrained_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Convert Dataset to TFRecords for TAO <a class=\"anchor\" id=\"head-3\"></a>\n",
    "\n",
    "* The `Detectnet_v2` model in TAO expects data in the form of TFRecords for training. \n",
    "* We can convert the KITTI Format Dataset generated from Part 1 with the `detectnet_v2 dataset_convert` tool provided with TAO toolkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Tfrecords for palletjack warehouse distractors dataset\n",
      "\n",
      "==============================\n",
      "=== TAO Toolkit TensorFlow ===\n",
      "==============================\n",
      "\n",
      "NVIDIA Release 4.0.0-TensorFlow (build )\n",
      "TAO Toolkit Version 4.0.0\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the TAO Toolkit End User License Agreement.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/tao-toolkit-software-license-agreement\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for TAO Toolkit.  NVIDIA recommends the use of the following flags:\n",
      "   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 10:35:08.312206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 10:35:14,201 [INFO] iva.detectnet_v2.dataio.build_converter: Instantiating a kitti converter\n",
      "2025-05-22 10:35:14,211 [INFO] iva.detectnet_v2.dataio.kitti_converter_lib: Num images in\n",
      "Train: 1800\tVal: 200\n",
      "2025-05-22 10:35:14,211 [INFO] iva.detectnet_v2.dataio.kitti_converter_lib: Validation data in partition 0. Hence, while choosing the validationset during training choose validation_fold 0.\n",
      "2025-05-22 10:35:14,212 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 0\n",
      "2025-05-22 10:35:14,435 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 1\n",
      "2025-05-22 10:35:14,666 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 2\n",
      "2025-05-22 10:35:14,887 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 3\n",
      "2025-05-22 10:35:15,094 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 4\n",
      "2025-05-22 10:35:15,331 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 5\n",
      "2025-05-22 10:35:15,548 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 6\n",
      "2025-05-22 10:35:15,742 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 7\n",
      "2025-05-22 10:35:15,959 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 8\n",
      "2025-05-22 10:35:16,175 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 9\n",
      "2025-05-22 10:35:16,391 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: \n",
      "Wrote the following numbers of objects:\n",
      "b'palletjack': 599\n",
      "\n",
      "2025-05-22 10:35:16,391 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 0\n",
      "2025-05-22 10:35:18,180 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 1\n",
      "2025-05-22 10:35:20,025 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 2\n",
      "2025-05-22 10:35:22,065 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 3\n",
      "2025-05-22 10:35:23,950 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 4\n",
      "2025-05-22 10:35:25,919 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 5\n",
      "2025-05-22 10:35:27,849 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 6\n",
      "2025-05-22 10:35:29,751 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 7\n",
      "2025-05-22 10:35:33,627 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 8\n",
      "2025-05-22 10:35:35,449 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 9\n",
      "2025-05-22 10:35:37,117 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: \n",
      "Wrote the following numbers of objects:\n",
      "b'palletjack': 5261\n",
      "\n",
      "2025-05-22 10:35:37,117 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Cumulative object statistics\n",
      "2025-05-22 10:35:37,118 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: \n",
      "Wrote the following numbers of objects:\n",
      "b'palletjack': 5860\n",
      "\n",
      "2025-05-22 10:35:37,118 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Class map. \n",
      "Label in GT: Label in tfrecords file \n",
      "b'palletjack': b'palletjack'\n",
      "For the dataset_config in the experiment_spec, please use labels in the tfrecords file, while writing the classmap.\n",
      "\n",
      "2025-05-22 10:35:37,118 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Tfrecords generation complete.\n",
      "Telemetry data couldn't be sent, but the command ran successfully.\n",
      "[WARNING]: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:852)>\n",
      "Execution status: PASS\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting Tfrecords for palletjack warehouse distractors dataset\")\n",
    "\n",
    "!mkdir -p $LOCAL_PROJECT_DIR/local/training/tao/tfrecords/distractors_warehouse && rm -rf $LOCAL_PROJECT_DIR/local/training/tao/tfrecords/distractors_warehouse/*\n",
    "\n",
    "!docker run -it --rm --gpus all -v $LOCAL_PROJECT_DIR:/workspace/tao-experiments $DOCKER_CONTAINER \\\n",
    "                   detectnet_v2 dataset_convert \\\n",
    "                  -d /workspace/tao-experiments/local/training/tao/specs/tfrecords/distractors_warehouse.txt \\\n",
    "                  -o /workspace/tao-experiments/local/training/tao/tfrecords/distractors_warehouse/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Tfrecords for palletjack with additional distractors\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "\n",
      "==============================\n",
      "=== TAO Toolkit TensorFlow ===\n",
      "==============================\n",
      "\n",
      "NVIDIA Release 4.0.0-TensorFlow (build )\n",
      "TAO Toolkit Version 4.0.0\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the TAO Toolkit End User License Agreement.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/tao-toolkit-software-license-agreement\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for TAO Toolkit.  NVIDIA recommends the use of the following flags:\n",
      "   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 10:36:43.822358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 10:36:49,587 [INFO] iva.detectnet_v2.dataio.build_converter: Instantiating a kitti converter\n",
      "2025-05-22 10:36:49,598 [INFO] iva.detectnet_v2.dataio.kitti_converter_lib: Num images in\n",
      "Train: 1800\tVal: 200\n",
      "2025-05-22 10:36:49,598 [INFO] iva.detectnet_v2.dataio.kitti_converter_lib: Validation data in partition 0. Hence, while choosing the validationset during training choose validation_fold 0.\n",
      "2025-05-22 10:36:49,599 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 0\n",
      "2025-05-22 10:36:49,813 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 1\n",
      "2025-05-22 10:36:50,048 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 2\n",
      "2025-05-22 10:36:50,263 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 3\n",
      "2025-05-22 10:36:50,480 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 4\n",
      "2025-05-22 10:36:50,725 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 5\n",
      "2025-05-22 10:36:50,935 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 6\n",
      "2025-05-22 10:36:51,143 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 7\n",
      "2025-05-22 10:36:51,327 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 8\n",
      "2025-05-22 10:36:51,540 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 9\n",
      "2025-05-22 10:36:51,783 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: \n",
      "Wrote the following numbers of objects:\n",
      "b'palletjack': 502\n",
      "\n",
      "2025-05-22 10:36:51,784 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 0\n",
      "2025-05-22 10:36:53,642 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 1\n",
      "2025-05-22 10:36:55,525 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 2\n",
      "2025-05-22 10:36:57,217 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 3\n",
      "2025-05-22 10:36:58,984 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 4\n",
      "2025-05-22 10:37:00,917 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 5\n",
      "2025-05-22 10:37:02,862 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 6\n",
      "2025-05-22 10:37:05,173 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 7\n",
      "2025-05-22 10:37:08,938 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 8\n",
      "2025-05-22 10:37:10,797 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 9\n",
      "2025-05-22 10:37:12,761 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: \n",
      "Wrote the following numbers of objects:\n",
      "b'palletjack': 4615\n",
      "\n",
      "2025-05-22 10:37:12,761 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Cumulative object statistics\n",
      "2025-05-22 10:37:12,761 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: \n",
      "Wrote the following numbers of objects:\n",
      "b'palletjack': 5117\n",
      "\n",
      "2025-05-22 10:37:12,761 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Class map. \n",
      "Label in GT: Label in tfrecords file \n",
      "b'palletjack': b'palletjack'\n",
      "For the dataset_config in the experiment_spec, please use labels in the tfrecords file, while writing the classmap.\n",
      "\n",
      "2025-05-22 10:37:12,761 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Tfrecords generation complete.\n",
      "Telemetry data couldn't be sent, but the command ran successfully.\n",
      "[WARNING]: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:852)>\n",
      "Execution status: PASS\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting Tfrecords for palletjack with additional distractors\")\n",
    "\n",
    "!mkdir -p $LOCAL_PROJECT_DIR/local/training/tao/tfrecords/distractors_additional && rm -rf $LOCAL_PROJECT_DIR/local/training/tao/tfrecords/distractors_additional/*\n",
    "\n",
    "!docker run -it --rm --gpus all -v $LOCAL_PROJECT_DIR:/workspace/tao-experiments $DOCKER_CONTAINER \\\n",
    "                   detectnet_v2 dataset_convert \\\n",
    "                  -d /workspace/tao-experiments/local/training/tao/specs/tfrecords/distractors_additional.txt \\\n",
    "                  -o /workspace/tao-experiments/local/training/tao/tfrecords/distractors_additional/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Tfrecords for kitti trainval dataset\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "\n",
      "==============================\n",
      "=== TAO Toolkit TensorFlow ===\n",
      "==============================\n",
      "\n",
      "NVIDIA Release 4.0.0-TensorFlow (build )\n",
      "TAO Toolkit Version 4.0.0\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the TAO Toolkit End User License Agreement.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/tao-toolkit-software-license-agreement\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for TAO Toolkit.  NVIDIA recommends the use of the following flags:\n",
      "   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 10:37:15.804526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 10:37:20,106 [INFO] iva.detectnet_v2.dataio.build_converter: Instantiating a kitti converter\n",
      "2025-05-22 10:37:20,115 [INFO] iva.detectnet_v2.dataio.kitti_converter_lib: Num images in\n",
      "Train: 900\tVal: 100\n",
      "2025-05-22 10:37:20,115 [INFO] iva.detectnet_v2.dataio.kitti_converter_lib: Validation data in partition 0. Hence, while choosing the validationset during training choose validation_fold 0.\n",
      "2025-05-22 10:37:20,116 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 0\n",
      "2025-05-22 10:37:20,232 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 1\n",
      "2025-05-22 10:37:20,335 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 2\n",
      "2025-05-22 10:37:20,438 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 3\n",
      "2025-05-22 10:37:20,532 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 4\n",
      "2025-05-22 10:37:20,632 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 5\n",
      "2025-05-22 10:37:20,732 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 6\n",
      "2025-05-22 10:37:20,834 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 7\n",
      "2025-05-22 10:37:20,921 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 8\n",
      "2025-05-22 10:37:21,026 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 0, shard 9\n",
      "2025-05-22 10:37:21,128 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: \n",
      "Wrote the following numbers of objects:\n",
      "b'palletjack': 312\n",
      "\n",
      "2025-05-22 10:37:21,128 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 0\n",
      "2025-05-22 10:37:22,120 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 1\n",
      "2025-05-22 10:37:23,003 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 2\n",
      "2025-05-22 10:37:23,965 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 3\n",
      "2025-05-22 10:37:24,941 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 4\n",
      "2025-05-22 10:37:25,943 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 5\n",
      "2025-05-22 10:37:26,950 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 6\n",
      "2025-05-22 10:37:27,937 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 7\n",
      "2025-05-22 10:37:28,973 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 8\n",
      "2025-05-22 10:37:30,035 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Writing partition 1, shard 9\n",
      "2025-05-22 10:37:31,104 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: \n",
      "Wrote the following numbers of objects:\n",
      "b'palletjack': 2924\n",
      "\n",
      "2025-05-22 10:37:31,104 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Cumulative object statistics\n",
      "2025-05-22 10:37:31,104 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: \n",
      "Wrote the following numbers of objects:\n",
      "b'palletjack': 3236\n",
      "\n",
      "2025-05-22 10:37:31,104 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Class map. \n",
      "Label in GT: Label in tfrecords file \n",
      "b'palletjack': b'palletjack'\n",
      "For the dataset_config in the experiment_spec, please use labels in the tfrecords file, while writing the classmap.\n",
      "\n",
      "2025-05-22 10:37:31,104 [INFO] iva.detectnet_v2.dataio.dataset_converter_lib: Tfrecords generation complete.\n",
      "Telemetry data couldn't be sent, but the command ran successfully.\n",
      "[WARNING]: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:852)>\n",
      "Execution status: PASS\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting Tfrecords for kitti trainval dataset\")\n",
    "# !mkdir -p $LOCAL_DATA_DIR/tfrecords/july/distractors_palletjack_warehouse && rm -rf $LOCAL_DATA_DIR/tfrecords/july/distractors_palletjack_warehouse/*\n",
    "!mkdir -p $LOCAL_PROJECT_DIR/local/training/tao/tfrecords/no_distractors && rm -rf $LOCAL_PROJECT_DIR/local/training/tao/tfrecords/no_distractors/*\n",
    "\n",
    "!docker run -it --rm --gpus all -v $LOCAL_PROJECT_DIR:/workspace/tao-experiments $DOCKER_CONTAINER \\\n",
    "                   detectnet_v2 dataset_convert \\\n",
    "                  -d /workspace/tao-experiments/local/training/tao/specs/tfrecords/no_distractors.txt \\\n",
    "                  -o /workspace/tao-experiments/local/training/tao/tfrecords/no_distractors/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Provide Training Specification File <a class=\"anchor\" id=\"head-4\"></a>\n",
    "\n",
    "* The spec file for training with TAO is provided under `$LOCAL_PROJECT_DIR/specs/training/resnet18_distractors.txt`\n",
    "* The tfrecords and the synthetic data generated in the previous steps are provided under the `dataset_config` parameter of the file\n",
    "* Other parameters like `augmentation_config`, `model_config`, `postprocessing_config` can be adjusted. Refer to [this](https://docs.nvidia.com/tao/tao-toolkit/text/object_detection/detectnet_v2.html) for a detailed guideline on adjusting the parameters in the spec file\n",
    "* For training our model to detect `palletjacks` this `spec` file provided can be used directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "random_seed: 42\n",
      "dataset_config {\n",
      "  data_sources {\n",
      "    tfrecords_path: \"/workspace/tao-experiments/local/training/tao/tfrecords/distractors_warehouse/*\"\n",
      "    image_directory_path: \"/workspace/tao-experiments/palletjack_sdg/palletjack_data/distractors_warehouse/Camera\"\n",
      "  }\n",
      "  \n",
      "  data_sources {\n",
      "    tfrecords_path: \"/workspace/tao-experiments/local/training/tao/tfrecords/distractors_additional/*\"\n",
      "    image_directory_path: \"/workspace/tao-experiments/palletjack_sdg/palletjack_data/distractors_additional/Camera\"\n",
      "  }\n",
      "  \n",
      "  data_sources {\n",
      "    tfrecords_path: \"/workspace/tao-experiments/local/training/tao/tfrecords/no_distractors/*\"\n",
      "    image_directory_path: \"/workspace/tao-experiments/palletjack_sdg/palletjack_data/no_distractors/Camera\"\n",
      "  }\n",
      "  \n",
      "  image_extension: \"png\"\n",
      "  \n",
      "  target_class_mapping {\n",
      "    key: \"palletjack\"\n",
      "    value: \"palletjack\"\n",
      "  }\n",
      "\n",
      " validation_fold: 0\n",
      "\n",
      "}\n",
      "\n",
      "augmentation_config {\n",
      "  preprocessing {\n",
      "    output_image_width: 960\n",
      "    output_image_height: 544\n",
      "    min_bbox_width: 20.0\n",
      "    min_bbox_height: 20.0\n",
      "    output_image_channel: 3\n",
      "  }\n",
      "  spatial_augmentation {\n",
      "    hflip_probability: 0.5\n",
      "    zoom_min: 0.5\n",
      "    zoom_max: 1.5\n",
      "    translate_max_x: 8.0\n",
      "    translate_max_y: 8.0\n",
      "  }\n",
      "  color_augmentation {\n",
      "    hue_rotation_max: 25.0\n",
      "    saturation_shift_max: 0.20000000298\n",
      "    contrast_scale_max: 0.10000000149\n",
      "    contrast_center: 0.5\n",
      "  }\n",
      "}\n",
      "\n",
      "postprocessing_config {\n",
      "  target_class_config {\n",
      "    key: \"palletjack\"\n",
      "    value {\n",
      "      clustering_config {\n",
      "        clustering_algorithm: DBSCAN\n",
      "        dbscan_confidence_threshold: 0.9\n",
      "        coverage_threshold: 0.00499999988824\n",
      "        dbscan_eps: 0.15000000596\n",
      "        dbscan_min_samples: 0.0500000007451\n",
      "        minimum_bounding_box_height: 20\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "model_config {\n",
      "  pretrained_model_file: \"/workspace/tao-experiments/local/training/tao/pretrained_model/resnet18.hdf5\"\n",
      "  num_layers: 18\n",
      "  use_batch_norm: true\n",
      "  objective_set {\n",
      "    bbox {\n",
      "      scale: 35.0\n",
      "      offset: 0.5\n",
      "    }\n",
      "    cov {\n",
      "    }\n",
      "  }\n",
      "  arch: \"resnet\"\n",
      "}\n",
      "\n",
      "evaluation_config {\n",
      "  validation_period_during_training: 10\n",
      "  first_validation_epoch: 5\n",
      "  minimum_detection_ground_truth_overlap {\n",
      "    key: \"palletjack\"\n",
      "    value: 0.5\n",
      "  }\n",
      "  evaluation_box_config {\n",
      "    key: \"palletjack\"\n",
      "    value {\n",
      "      minimum_height: 25\n",
      "      maximum_height: 9999\n",
      "      minimum_width: 25\n",
      "      maximum_width: 9999\n",
      "    }\n",
      "  }\n",
      "  average_precision_mode: INTEGRATE\n",
      "}\n",
      "\n",
      "cost_function_config {\n",
      "  target_classes {\n",
      "    name: \"palletjack\"\n",
      "    class_weight: 1.0\n",
      "    coverage_foreground_weight: 0.0500000007451\n",
      "    objectives {\n",
      "      name: \"cov\"\n",
      "      initial_weight: 1.0\n",
      "      weight_target: 1.0\n",
      "    }\n",
      "    objectives {\n",
      "      name: \"bbox\"\n",
      "      initial_weight: 10.0\n",
      "      weight_target: 1.0\n",
      "    }\n",
      "  }\n",
      "  enable_autoweighting: true\n",
      "  max_objective_weight: 0.999899983406\n",
      "  min_objective_weight: 9.99999974738e-05\n",
      "}\n",
      "\n",
      "training_config {\n",
      "  batch_size_per_gpu: 32\n",
      "  num_epochs: 100\n",
      "  learning_rate {\n",
      "    soft_start_annealing_schedule {\n",
      "      min_learning_rate: 5e-06\n",
      "      max_learning_rate: 5e-04\n",
      "      soft_start: 0.10000000149\n",
      "      annealing: 0.699999988079\n",
      "    }\n",
      "  }\n",
      "  regularizer {\n",
      "    type: L1\n",
      "    weight: 3.00000002618e-09\n",
      "  }\n",
      "  optimizer {\n",
      "    adam {\n",
      "      epsilon: 9.99999993923e-09\n",
      "      beta1: 0.899999976158\n",
      "      beta2: 0.999000012875\n",
      "    }\n",
      "  }\n",
      "  cost_scaling {\n",
      "    initial_exponent: 20.0\n",
      "    increment: 0.005\n",
      "    decrement: 1.0\n",
      "  }\n",
      "  visualizer{\n",
      "    enabled: true\n",
      "    num_images: 10\n",
      "    scalar_logging_frequency: 10\n",
      "    infrequent_logging_frequency: 5\n",
      "    target_class_config {\n",
      "      key: \"palletjack\"\n",
      "      value: {\n",
      "        coverage_threshold: 0.005\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  checkpoint_interval: 10\n",
      "}\n",
      "\n",
      "bbox_rasterizer_config {\n",
      "  target_class_config {\n",
      "    key: \"palletjack\"\n",
      "    value {\n",
      "      cov_center_x: 0.5\n",
      "      cov_center_y: 0.5\n",
      "      cov_radius_x: 1.0\n",
      "      cov_radius_y: 1.0\n",
      "      bbox_min_radius: 1.0\n",
      "    }\n",
      "  }\n",
      "  deadzone_radius: 0.400000154972\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat $LOCAL_PROJECT_DIR/local/training/tao/specs/training/resnet18_distractors.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters can be set in the `spec` file. Adjust batch size parameter depending on the VRAM of your GPU \n",
    "\n",
    "* You can increase the number of epochs, the number of false positives in real world images keeps decreasing (mAP does not change much after ~250 epochs and usually results in the best trained model for the given dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run TAO Training <a class=\"anchor\" id=\"head-5\"></a>\n",
    "\n",
    "* The `$LOCAL_PROJECT_DIR` will be mounted to the TAO docker for training, this contains all the data, pretrained model and spec files (training and inference) needed\n",
    "\n",
    "#### Ensure that no `_warning.json` file exists in the `$LOCAL_PROJECT_DIR/cloud/training/tao/tfrecords` sub-folders (`distractors_additional`, `ditractors_warehouse` and `no_distractors`)\n",
    "* Delete the `_warning.json` files before beginning training\n",
    "* TAO training won't begin if the structure of the `tfrecords` folder directories is not as expected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KEY=tlt_encode\n",
      "env: NUM_GPUS=1\n"
     ]
    }
   ],
   "source": [
    "# Setting up env variables for cleaner command line commands.\n",
    "%env KEY=tlt_encode\n",
    "%env NUM_GPUS=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TAO Training can be stopped and resumed (`checkpoint_interval` parameter specified in the `spec` file)\n",
    "* Tensorboard visualization can be used with TAO [instructions](https://docs.nvidia.com/tao/tao-toolkit/text/tensorboard_visualization.html#visualizing-using-tensorboard). \n",
    "* The `$RESULTS_DIR` parameter is the folder where the `$LOCAL_PROJECT_DIR/local/training/tao/detectnet_v2/resnet18_palletjack` folder which is specified with the `-i` flag in the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "\n",
      "==============================\n",
      "=== TAO Toolkit TensorFlow ===\n",
      "==============================\n",
      "\n",
      "NVIDIA Release 4.0.0-TensorFlow (build )\n",
      "TAO Toolkit Version 4.0.0\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the TAO Toolkit End User License Agreement.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/tao-toolkit-software-license-agreement\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for TAO Toolkit.  NVIDIA recommends the use of the following flags:\n",
      "   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 15:03:18.945773: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 15:03:25,644 [INFO] iva.common.logging.logging: Log file already exists at /workspace/tao-experiments/local/training/tao/detectnet_v2/resnet18_palletjack/status.json\n",
      "2025-05-22 15:03:25,646 [INFO] root: Starting DetectNet_v2 Training job\n",
      "2025-05-22 15:03:25,647 [INFO] __main__: Loading experiment spec at /workspace/tao-experiments/local/training/tao/specs/training/resnet18_distractors.txt.\n",
      "2025-05-22 15:03:25,650 [INFO] iva.detectnet_v2.spec_handler.spec_loader: Merging specification from /workspace/tao-experiments/local/training/tao/specs/training/resnet18_distractors.txt\n",
      "2025-05-22 15:03:25,659 [INFO] root: Training gridbox model.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2025-05-22 15:03:25,660 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2025-05-22 15:03:26,497 [INFO] root: Sampling mode of the dataloader was set to user_defined.\n",
      "2025-05-22 15:03:26,497 [INFO] __main__: Cannot iterate over exactly 4500 samples with a batch size of 32; each epoch will therefore take one extra step.\n",
      "2025-05-22 15:03:26,513 [INFO] root: Building DetectNet V2 model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2025-05-22 15:03:26,513 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2025-05-22 15:03:26,514 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2025-05-22 15:03:26,529 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "2025-05-22 15:03:27,175 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/third_party/keras/tensorflow_backend.py:187: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2025-05-22 15:03:27,511 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2025-05-22 15:03:27,511 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2025-05-22 15:03:27,511 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2025-05-22 15:03:27,801 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2025-05-22 15:03:33,297 [INFO] iva.detectnet_v2.objectives.bbox_objective: Default L1 loss function will be used.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 544, 960)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 272, 480) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 272, 480) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 272, 480) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 136, 240) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 136, 240) 256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 136, 240) 0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 136, 240) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 136, 240) 0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 136, 240) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 68, 120) 73856       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 68, 120) 8320        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 68, 120) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 68, 120) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 68, 120) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 68, 120) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 68, 120) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 34, 60)  295168      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 34, 60)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 34, 60)  590080      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 34, 60)  33024       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 34, 60)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 34, 60)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 34, 60)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 34, 60)  590080      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 34, 60)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 34, 60)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 34, 60)  590080      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 34, 60)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 34, 60)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 512, 34, 60)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 512, 34, 60)  2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 512, 34, 60)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 34, 60)  2359808     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 34, 60)  131584      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 34, 60)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 34, 60)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 34, 60)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 34, 60)  2359808     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 34, 60)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 34, 60)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 34, 60)  2359808     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 34, 60)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 34, 60)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_bbox (Conv2D)            (None, 4, 34, 60)    2052        block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_cov (Conv2D)             (None, 1, 34, 60)    513         block_4b_relu[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 11,197,893\n",
      "Trainable params: 11,188,165\n",
      "Non-trainable params: 9,728\n",
      "__________________________________________________________________________________________________\n",
      "2025-05-22 15:03:33,321 [INFO] root: DetectNet V2 model built.\n",
      "2025-05-22 15:03:33,322 [INFO] root: Building rasterizer.\n",
      "2025-05-22 15:03:33,323 [INFO] root: Rasterizers built.\n",
      "2025-05-22 15:03:33,339 [INFO] root: Building training graph.\n",
      "2025-05-22 15:03:33,340 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2025-05-22 15:03:33,341 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2025-05-22 15:03:33,341 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): [0, 0]\n",
      "2025-05-22 15:03:33,341 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 24, io threads: 48, compute threads: 24, buffered batches: 4\n",
      "2025-05-22 15:03:33,341 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 4500, number of sources: 3, batch size per gpu: 32, steps: 141\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2025-05-22 15:03:33,372 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90dd8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90dd8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:03:33,401 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90dd8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90dd8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:03:33,416 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2025-05-22 15:03:33,579 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: True - shard 0 of 1\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90e10>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:03:33,592 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90e10>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:03:33,607 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2025-05-22 15:03:33,751 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: True - shard 0 of 1\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90e80>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:03:33,764 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90e80>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7fd052e90e80>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:03:33,779 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2025-05-22 15:03:33,936 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: True - shard 0 of 1\n",
      "2025-05-22 15:03:33,939 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 3 datasets with weights:\n",
      "2025-05-22 15:03:33,940 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 0.400000\n",
      "2025-05-22 15:03:33,940 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 1 weight: 0.400000\n",
      "2025-05-22 15:03:33,940 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 2 weight: 0.200000\n",
      "WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fcf886079e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fcf886079e8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:03:33,959 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fcf886079e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7fcf886079e8>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:03:34,189 [INFO] __main__: Found 4500 samples in training set\n",
      "2025-05-22 15:03:34,193 [INFO] root: Rasterizing tensors.\n",
      "2025-05-22 15:03:34,326 [INFO] root: Tensors rasterized.\n",
      "^C\n",
      "Command was interrupted.\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm --gpus all -v $LOCAL_PROJECT_DIR:/workspace/tao-experiments $DOCKER_CONTAINER \\\n",
    "            detectnet_v2 train -e /workspace/tao-experiments/local/training/tao/specs/training/resnet18_distractors.txt \\\n",
    "            -r /workspace/tao-experiments/local/training/tao/detectnet_v2/resnet18_palletjack -k $KEY --gpus $NUM_GPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Trained Model <a class=\"anchor\" id=\"head-6\"></a>\n",
    "\n",
    "* While generating the `tfrecords` part of the total data generated was kept as a validation set (14% of total data)\n",
    "* We will run our model evaluation on this data to obtain metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "\n",
      "==============================\n",
      "=== TAO Toolkit TensorFlow ===\n",
      "==============================\n",
      "\n",
      "NVIDIA Release 4.0.0-TensorFlow (build )\n",
      "TAO Toolkit Version 4.0.0\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the TAO Toolkit End User License Agreement.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/tao-toolkit-software-license-agreement\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for TAO Toolkit.  NVIDIA recommends the use of the following flags:\n",
      "   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 15:03:56.803250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 15:04:01,014 [INFO] iva.detectnet_v2.spec_handler.spec_loader: Merging specification from /workspace/tao-experiments/local/training/tao/specs/training/resnet18_distractors.txt\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2025-05-22 15:04:01,021 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:153: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "2025-05-22 15:04:01,174 [INFO] root: Loading model weights.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "2025-05-22 15:04:13,178 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "2025-05-22 15:04:13,183 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "2025-05-22 15:04:13,197 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "2025-05-22 15:04:13,673 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2025-05-22 15:04:13,673 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "2025-05-22 15:04:13,673 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "2025-05-22 15:04:13,809 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "2025-05-22 15:04:14,111 [INFO] iva.detectnet_v2.objectives.bbox_objective: Default L1 loss function will be used.\n",
      "2025-05-22 15:04:14,111 [INFO] root: Building dataloader.\n",
      "2025-05-22 15:04:15,131 [INFO] root: Sampling mode of the dataloader was set to user_defined.\n",
      "2025-05-22 15:04:15,132 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2025-05-22 15:04:15,132 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2025-05-22 15:04:15,132 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): [0, 0]\n",
      "2025-05-22 15:04:15,132 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 24, io threads: 48, compute threads: 24, buffered batches: 4\n",
      "2025-05-22 15:04:15,132 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 500, number of sources: 3, batch size per gpu: 32, steps: 16\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "2025-05-22 15:04:15,156 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95be0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95be0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:04:15,183 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95be0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95be0>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:04:15,201 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2025-05-22 15:04:15,350 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95978>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:04:15,360 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95978>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:04:15,375 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2025-05-22 15:04:15,506 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "WARNING:tensorflow:Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95e10>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:04:15,516 [WARNING] tensorflow: Entity <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method DriveNetTFRecordsParser.__call__ of <iva.detectnet_v2.dataloader.drivenet_dataloader.DriveNetTFRecordsParser object at 0x7f28f4e95e10>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:04:15,531 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2025-05-22 15:04:15,679 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2025-05-22 15:04:15,682 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 3 datasets with weights:\n",
      "2025-05-22 15:04:15,682 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 0.400000\n",
      "2025-05-22 15:04:15,682 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 1 weight: 0.400000\n",
      "2025-05-22 15:04:15,682 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 2 weight: 0.200000\n",
      "WARNING:tensorflow:Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f287408b160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f287408b160>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:04:15,701 [WARNING] tensorflow: Entity <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f287408b160>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Unable to locate the source code of <bound method Processor.__call__ of <modulus.blocks.data_loaders.multi_source_loader.processors.asset_loader.AssetLoader object at 0x7f287408b160>>. Note that functions defined in certain environments, like the interactive Python shell do not expose their source code. If that is the case, you should to define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.do_not_convert. Original error: could not get source code\n",
      "2025-05-22 15:04:15,838 [INFO] iva.detectnet_v2.evaluation.build_evaluator: Found 500 samples in validation set\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 544, 960)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 272, 480) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 272, 480) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 272, 480) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 136, 240) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 136, 240) 256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 136, 240) 0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 136, 240) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 136, 240) 0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 136, 240) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 68, 120) 73856       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 68, 120) 8320        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 68, 120) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 68, 120) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 68, 120) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 68, 120) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 68, 120) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 34, 60)  295168      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 34, 60)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 34, 60)  590080      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 34, 60)  33024       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 34, 60)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 34, 60)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 34, 60)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 34, 60)  590080      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 34, 60)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 34, 60)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 34, 60)  590080      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 34, 60)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 34, 60)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 512, 34, 60)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 512, 34, 60)  2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 512, 34, 60)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 34, 60)  2359808     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 34, 60)  131584      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 34, 60)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 34, 60)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 34, 60)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 34, 60)  2359808     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 34, 60)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 34, 60)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 34, 60)  2359808     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 34, 60)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 34, 60)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_bbox (Conv2D)            (None, 4, 34, 60)    2052        block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_cov (Conv2D)             (None, 1, 34, 60)    513         block_4b_relu[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 11,197,893\n",
      "Trainable params: 11,188,165\n",
      "Non-trainable params: 9,728\n",
      "__________________________________________________________________________________________________\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2025-05-22 15:04:16,409 [INFO] tensorflow: Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "2025-05-22 15:04:16,800 [INFO] tensorflow: Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "2025-05-22 15:04:17,327 [INFO] tensorflow: Done running local_init_op.\n",
      "2025-05-22 15:04:18,071 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 16, 0.00s/step\n",
      "2025-05-22 15:04:27,559 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 16, 0.95s/step\n",
      "Matching predictions to ground truth, class 1/1.: 100%|█| 8380/8380 [00:00<00:00, 35383.00it/s]\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "2025-05-22 15:04:29,547 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "2025-05-22 15:04:29,547 [WARNING] tensorflow: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "\n",
      "Validation cost: 0.002186\n",
      "Mean average_precision (in %): 80.3950\n",
      "\n",
      "class name      average precision (in %)\n",
      "------------  --------------------------\n",
      "palletjack                        80.395\n",
      "\n",
      "Median Inference Time: 0.004446\n",
      "2025-05-22 15:04:29,586 [INFO] __main__: Evaluation complete.\n",
      "Time taken to run __main__:main: 0:00:28.576293.\n",
      "Telemetry data couldn't be sent, but the command ran successfully.\n",
      "[WARNING]: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:852)>\n",
      "Execution status: PASS\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm --gpus all -v $LOCAL_PROJECT_DIR:/workspace/tao-experiments $DOCKER_CONTAINER \\\n",
    "            detectnet_v2 evaluate -e /workspace/tao-experiments/local/training/tao/specs/training/resnet18_distractors.txt \\\n",
    "            -m /workspace/tao-experiments/local/training/tao/detectnet_v2/resnet18_palletjack/weights/model.tlt \\\n",
    "            -k $KEY --gpus $NUM_GPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Model Performance on Real World Data <a class=\"anchor\" id=\"head-7\"></a>\n",
    "\n",
    "* Lets visualize the model predictions on a few sample real world images next\n",
    "* We will use palletjack images in a warehouse from the `LOCO` dataset to understand if the model is capable of performing real world detections\n",
    "* Additional images can be placed under the `loco_palletjacks` folder of this project. The input folder is specified with the `-i` flag in the command below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
      "\n",
      "==============================\n",
      "=== TAO Toolkit TensorFlow ===\n",
      "==============================\n",
      "\n",
      "NVIDIA Release 4.0.0-TensorFlow (build )\n",
      "TAO Toolkit Version 4.0.0\n",
      "\n",
      "Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the TAO Toolkit End User License Agreement.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/tao-toolkit-software-license-agreement\n",
      "\n",
      "NOTE: The SHMEM allocation limit is set to the default of 64MB.  This may be\n",
      "   insufficient for TAO Toolkit.  NVIDIA recommends the use of the following flags:\n",
      "   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...\n",
      "\n",
      "Using TensorFlow backend.\n",
      "2025-05-22 15:28:31.059398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "/usr/local/lib/python3.6/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "INFO: Merging specification from /workspace/tao-experiments/local/training/tao/specs/inference/new_inference_specs.txt\n",
      "INFO: Overlain images will be saved in the output path.\n",
      "INFO: Constructing inferencer\n",
      "INFO: Loading model from /workspace/tao-experiments/local/training/tao/detectnet_v2/resnet18_palletjack/weights/model.tlt:\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING: From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 544, 960)       0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              [(None, 1, 34, 60), (None 11197893  \n",
      "=================================================================\n",
      "Total params: 11,197,893\n",
      "Trainable params: 11,188,165\n",
      "Non-trainable params: 9,728\n",
      "_________________________________________________________________\n",
      "INFO: Initialized model\n",
      "INFO: Commencing inference\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:04<00:00,  4.61s/it]\n",
      "INFO: Inference complete\n",
      "Telemetry data couldn't be sent, but the command ran successfully.\n",
      "[WARNING]: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:852)>\n",
      "Execution status: PASS\n"
     ]
    }
   ],
   "source": [
    "!docker run -it --rm --gpus all -v $LOCAL_PROJECT_DIR:/workspace/tao-experiments $DOCKER_CONTAINER \\\n",
    "                            detectnet_v2 inference -e /workspace/tao-experiments/local/training/tao/specs/inference/new_inference_specs.txt \\\n",
    "                            -o /workspace/tao-experiments/local/training/tao/detectnet_v2/resnet18_palletjack/5k_model_synthetic \\\n",
    "                            -i /workspace/tao-experiments/images/sample_synthetic \\\n",
    "                            -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/c/labs/synthetic_data_generation_training_workflow/local/training/tao/detectnet_v2/resnet18_palletjack/test_loco/images_annotated/1564562568.298206.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# pil_img = Image(filename=os.path.join(os.getenv(\"LOCAL_PROJECT_DIR\"), 'detecnet_v2/july_resnet18_trials/new_pellet_distractors_10k/test_loco/images_annotated/1564562568.298206.jpg'))\u001b[39;00m\n\u001b[1;32m      6\u001b[0m image_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1564562568.298206.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1564562628.517229.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1564562843.0618184.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m593768,3659.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m516447400,977.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \n\u001b[0;32m----> 8\u001b[0m images \u001b[38;5;241m=\u001b[39m [Image(filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(results_dir, image_name)) \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m image_names]\n\u001b[1;32m     10\u001b[0m display(\u001b[38;5;241m*\u001b[39mimages)\n",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# pil_img = Image(filename=os.path.join(os.getenv(\"LOCAL_PROJECT_DIR\"), 'detecnet_v2/july_resnet18_trials/new_pellet_distractors_10k/test_loco/images_annotated/1564562568.298206.jpg'))\u001b[39;00m\n\u001b[1;32m      6\u001b[0m image_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1564562568.298206.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1564562628.517229.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1564562843.0618184.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m593768,3659.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m516447400,977.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m] \n\u001b[0;32m----> 8\u001b[0m images \u001b[38;5;241m=\u001b[39m [\u001b[43mImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m image_names]\n\u001b[1;32m     10\u001b[0m display(\u001b[38;5;241m*\u001b[39mimages)\n",
      "File \u001b[0;32m~/miniconda3/envs/jlab/lib/python3.10/site-packages/IPython/core/display.py:1053\u001b[0m, in \u001b[0;36mImage.__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munconfined \u001b[38;5;241m=\u001b[39m unconfined\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malt \u001b[38;5;241m=\u001b[39m alt\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, {}):\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/jlab/lib/python3.10/site-packages/IPython/core/display.py:371\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_data()\n",
      "File \u001b[0;32m~/miniconda3/envs/jlab/lib/python3.10/site-packages/IPython/core/display.py:1088\u001b[0m, in \u001b[0;36mImage.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m-> 1088\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mImage\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretina:\n\u001b[1;32m   1090\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retina_shape()\n",
      "File \u001b[0;32m~/miniconda3/envs/jlab/lib/python3.10/site-packages/IPython/core/display.py:397\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    396\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_flags \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# Deferred import\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/c/labs/synthetic_data_generation_training_workflow/local/training/tao/detectnet_v2/resnet18_palletjack/test_loco/images_annotated/1564562568.298206.jpg'"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image \n",
    "\n",
    "results_dir = os.path.join(os.environ[\"LOCAL_PROJECT_DIR\"], \"local/training/tao/detectnet_v2/resnet18_palletjack/test_loco/images_annotated\")\n",
    "# pil_img = Image(filename=os.path.join(os.getenv(\"LOCAL_PROJECT_DIR\"), 'detecnet_v2/july_resnet18_trials/new_pellet_distractors_10k/test_loco/images_annotated/1564562568.298206.jpg'))\n",
    "                           \n",
    "image_names = [\"1564562568.298206.jpg\", \"1564562628.517229.jpg\", \"1564562843.0618184.jpg\", \"593768,3659.jpg\", \"516447400,977.jpg\"] \n",
    "                           \n",
    "images = [Image(filename = os.path.join(results_dir, image_name)) for image_name in image_names]\n",
    "\n",
    "display(*images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps <a class=\"anchor\" id=\"head-8\"></a>\n",
    "\n",
    "#### Generating Synthetic Data for your use case:\n",
    "\n",
    "* Make changes in the Domain Randomization under the Synthetic Data Generation script (`palletjack_sdg/standalone_palletjack_sdg.py`\n",
    "* Add additional objects of interest in the scene (similar to how `palletjacks` are added, you can add `forklifts`, `ladders` etc.) to generate data\n",
    "* Use [different](https://docs.nvidia.com/tao/tao-toolkit/text/tao_toolkit_quick_start_guide.html#downloading-the-models) models for training with TAO (for object detection, you can use `YOLO`, `SSD`, `EfficientDet`) \n",
    "* Replicator provides Semantic Segmentation, Instance Segmentation, Depth and various other ground truth annotations along with RGB. You can also write your own ground truth annotator (eg: Pose Estimation: Refer to [sample](https://docs.omniverse.nvidia.com/isaacsim/latest/tutorial_replicator_offline_pose_estimation.html). These can be used for training a model of your own framework and choice\n",
    "* Exploring the option of using `Synthetic + Real` data for training a network. Can be particularly useful for generating more data around particular corner cases\n",
    "\n",
    "\n",
    "#### Deploying Trained Models:\n",
    "\n",
    "* After obtaining satisfactory results with the training process, you can further optimize your model for deployment with the help of Pruning and QAT.\n",
    "* TAO models can directly be deployed on Jetson with Isaac ROS or Deepstream which ensures your end-to-end pipeline being optimized (data acquisition -> model inference -> results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f23a2831654361cfd8b219e05b5055fdda3e37fe5c0b020e6226f740844c300a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
